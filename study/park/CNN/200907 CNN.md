# 합성곱 신경망 (Convolutional Neural Networks)

![image-20200907225413505](images/image-20200907225413505.png)



### 완전연결 계층 (Fully-connected layer)의 문제점

* 이미지 데이터의 경우 세로, 가로, 채널의 3차원 형상을 가지며, **공간적 구조(spatial structure)**를 가짐
  * 공간적으로 가까운 픽셀은 값이 비슷함
  * RGB의 각 채널은 서로 밀접한 관련이 있음
  * 거리가 먼 픽셀끼리는 관련이 없음
* 데이터를 1차원의 평평한(flat) 형태로 펼쳐줘야 함 -> **데이터의 형상이 무시됨** -> 위와 같은 정보들이 사라짐



### 합성곱층 (Convolutional layer)

* CNN에서 가장 중요한 구성 요소
* 완전연결 계층과는 달리 입력 **데이터의 형상을 유지함**
* 합성곱층의 뉴런은 입력 이미지의 모든 픽셀에 연결되는 것이 아니라 합성곱층 뉴런의 **수용영역(receptive field) 안에 있는 픽셀에만 연결됨**



### 필터 (Filter)

* 위의 수용영역을 합성곱층에서 **필터(filter)** 또는 **커널(kernel)**이라 함
* 합성곱층에서의 가중치 파라미터(W)에 해당됨
* 학습 단계에서 적절한 필터를 찾도록 학습되며, 합성곱층에서 입력 데이터에 필터를 적용하여 필터와 유사한 이미지의 영역을 강조하는 **특성맵(feature map)**을 출력하여 다음 층으로 전달함



### 합성곱 (Convolution) vs 교차 상관 (Cross-correlation)

* 합성곱 : 하나의 함수와 또 다른 함수를 **반전** 이동한 값을 곱한 다음, 구간에 대해 적분하여 새로운 함수를 구하는 연산자

  ![image-20200907224132280](images/image-20200907224132280.png)

  ![image-20200907224148302](images/image-20200907224148302.png)

* 교차 상관 : 하나의 함수와 또 다른 함수를 이동한 값을 곱한 다음, 구간에 대해 적분하여 새로운 함수를 구하는 연산자

  ![image-20200907224216776](images/image-20200907224216776.png)

  ![image-20200907224226944](images/image-20200907224226944.png)

* 합성곱 연산을 하려면 필터를 뒤집은 다음 적용해야 함 -> CNN에서는 필터의 값을 학습하는 것이 목적 -> 합성곱을 적용하나 교차 상관을 적용하나 동일함 -> CNN의 합성곱층에서는 합성곱이 아닌 교차 상관을 사용함 (Tensor flow나 다른 딥러닝 프레임워크들에서)



### 합성곱층 연산

* 데이터와 필터의 모양을 (높이, 너비)로 나타내고 윈도우(Window)라고 부름
* 필터의 윈도우를 일정한 간격으로 이동해가면 계산함
* 입력 데이터와 필터가 대응하는 원소끼리 곱한 후 총합을 구함
* 편향(bias)은 필터를 적용한 후에 더함

![image-20200907224909195](images/image-20200907224909195.png)



### 패딩 (padding)

* 합성곱 연산을 수행하기 전, 입력 데이터 주변을 특정값으로 채워 늘리는 것을 말함
* 주로 출력 데이터의 공간적 크기를 조절하기 위해 사용함 (가장자리의 정보들이 누락되는 것을 막아줌)
* 주로 **zero-padding**을 사용함

![image-20200907224925073](images/image-20200907224925073.png)



### 스트라이드(Stride)

* **필터가 이동하는 간격**
* 스트라이드 또한 출력 데이터의 크기를 조절하기 위해 사용함



### 3차원 데이터의 합성곱

* **입력 데이터의 채널 수와 필터의 채널 수가 같아야 한다!!**

  ![image-20200907225143996](images/image-20200907225143996.png)

* **출력 데이터의 채널 수와 사용한 필터의 개수가 같아야 한다!!**





### 2D Convolution Layer - 4D Tensors

* 2D -> 필터가 이동하는 것이 2차원 (가로, 세로)
* 입력 데이터, 필터, 출력 데이터 모두 4D Tensor 형태



### Activation Function

* ReLU (가장 많이 사용함)

  ![image-20200907230127232](images/image-20200907230127232.png)

  * 음수는 0으로 바꿔주고 양수는 그대로 통과시킴

  

### 실습 코드

#### 각 parameter의 의미

![image-20200907230531016](images/image-20200907230531016.png)

![image-20200907230307651](images/image-20200907230307651.png)

![image-20200907230343327](images/image-20200907230343327.png)

![image-20200907230415980](images/image-20200907230415980.png)



#### 실습 코드

![image-20200907230648354](images/image-20200907230648354.png)

![image-20200907230717791](images/image-20200907230717791.png)



* `padding = 'VALID'`인 경우

![image-20200907230740701](images/image-20200907230740701.png)

![image-20200907230759462](images/image-20200907230759462.png)



* `padding = 'SAME'`인 경우

![image-20200907230836684](images/image-20200907230836684.png)

![image-20200907230901206](images/image-20200907230901206.png)



* 필터를 여러 개 사용하는 경우

![image-20200907230924766](images/image-20200907230924766.png)

